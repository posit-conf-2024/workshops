[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "posit::conf(2024) workshops",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Instructor(s)\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nInstructor(s)\n\n\nDescription\n\n\nSubtitle\n\n\n\n\n\n\nAdvanced Tidymodels\n\n\nMax Kuhn\n\n\nAn advanced class to learn how to use tidymodels to optimize different models, conduct feature engineering, and other activities. \n\n\n \n\n\n\n\nBig Data in R with Arrow\n\n\nNic Crane, Steph Hazlitt\n\n\nAn introduction to Apache Arrow for creating efficient analysis pipelines with larger-than-memory data in R. \n\n\nhttps://posit-conf-2024.github.io/arrow\n\n\n\n\nBuild-a-Dashboard Workshop (with Quarto, R and/or Python)\n\n\nMine Çetinkaya-Rundel\n\n\nCreate sleek, elegant, and eye-catching dashboards with static and/or interactive elements with Quarto. For R and Python users. \n\n\nhttps://github.com/posit-conf-2024/quarto-dashboards\n\n\n\n\nCausal Inference in R\n\n\nMalcolm Barrett, Travis Gerke\n\n\nLearn to answer causal questions with causal diagrams, propensity score modeling, and more. \n\n\nhttps://r-causal.github.io/causal_workshop_website\n\n\n\n\nData Science Workflows with Posit Tools — Python Focus\n\n\nSam Edwardes, Gagandeep Singh\n\n\nBuild an opinionated and Pythonic data science workflow using Posit’s professional products and open-source tools. \n\n\nhttps://ferryland.posit.team\n\n\n\n\nData Science Workflows with Posit Tools — R Focus\n\n\nRyan Johnson, Katie Masiello\n\n\nUse open source packages and Posit’s professional tools — Workbench, Connect, and Package Manager — to improve your end-to-end data science workflows. \n\n\nhttps://github.com/posit-conf-2024/ds-workflows-r\n\n\n\n\nDatabases with R\n\n\nKirill Müller\n\n\nAn introduction to databases and DuckDB with R. \n\n\nhttps://github.com/posit-conf-2024/databases\n\n\n\n\nDevOps for Data Scientists\n\n\nRika Gorn\n\n\nThis workshop is intended for data scientists who wish to learn more about the basic principles and tools of DevOps and to get hands-on experience putting DevOps workflows into production. \n\n\nhttps://github.com/posit-conf-2024/dev-ops\n\n\n\n\nEffective data visualization with ggplot2\n\n\nClaus O. Wilke\n\n\nLevel up your figure design skills with advanced tips and tricks for ggplot2 and with fundamental principles of visual communication. \n\n\nhttps://github.com/posit-conf-2024/dataviz-r\n\n\n\n\nFlavors of the pharmaverse\n\n\nDaniel D. Sjoberg, Becca Krouse, Ellis Hughes, Andrew Bates, Casey Aguilar-Gervase\n\n\nHigh level overview of the scope and tools available within the pharmaverse for the clinical pipeline, including tools for ADaM data set curation, creating Analysis Results Data Sets, and TLGs. \n\n\nhttps://posit-conf-2024.github.io/pharmaverse/\n\n\n\n\nFrom R User to R Programmer\n\n\nEmma Rand, Ian Lyttle\n\n\nImprove your R programming skills and reduce the amount of duplication in your code. \n\n\nhttps://github.com/posit-conf-2024/programming-r\n\n\n\n\nIntro to MLOps with vetiver\n\n\nIsabel Zimmerman, Julia Silge\n\n\nUtilize the vetiver framework in Python and R for efficient versioning, deployment, and monitoring of machine learning models in production. \n\n\nhttps://posit-conf-2024.github.io/vetiver\n\n\n\n\nIntroduction to Data Science with Python\n\n\nPosit Academy Team\n\n\nLearn the foundations of Python for data science through a cohort-based, mentor-led, hands-on apprenticeship for working professionals. \n\n\nNEED LINK\n\n\n\n\nIntroduction to Data Science with R and Tidyverse\n\n\nPosit Academy Team\n\n\nLearn the foundations of R for data science through a cohort-based, mentor-led, hands-on apprenticeship for working professionals. \n\n\nhttps://intro-tidyverse-2024.netlify.app\n\n\n\n\nIntroduction to Quarto\n\n\nAndrew Bray\n\n\nAuthor a rich array of documents in Quarto. \n\n\nhttps://github.com/posit-conf-2024/quarto-intro\n\n\n\n\nIntroduction to Shiny for Python\n\n\nGarrett Grolemund, Andrie de Vries\n\n\nLearn the basic building blocks of Shiny for Python, including the new Shiny Express syntax. \n\n\nhttps://posit-conf-2024.github.io/intro-to-shiny-for-python\n\n\n\n\nIntroduction to Shiny for R\n\n\nColin Rundel\n\n\nIntroduction to builing interactive web apps using Shiny and R \n\n\nhttps://posit-conf-2024.github.io/shiny-r-intro\n\n\n\n\nIntroduction to machine learning in Python with Scikit-learn\n\n\nTiffany Timbers, Trevor Campbell\n\n\nMachine learning with tabular data using Python’s the Scikit-learn framework. \n\n\nhttps://posit-conf-2024.github.io/ml-python\n\n\n\n\nIntroduction to tidymodels\n\n\nHannah Frick, Simon Couch\n\n\nMachine learning with tabular data using the tidymodels framework. \n\n\nhttps://workshops.tidymodels.org\n\n\n\n\nLevel Up with Shiny for R\n\n\nGarrick Aden-Buie\n\n\nLevel up your Shiny skills to build complex applications with brilliant user interfaces. \n\n\nhttps://posit-conf-2024.github.io/level-up-shiny\n\n\n\n\nMaking Tables with gt and Great Tables\n\n\nRichard Iannone, Michael Chow\n\n\nCreate publication-quality tables with gt and Great Tables. For R and Python users. \n\n\n \n\n\n\n\nPackage Development: The Rest of the Owl\n\n\nJenny Bryan\n\n\nLearn what’s different about writing R code that lives in a package (vs. a script). \n\n\nhttps://pos.it/pkg_dev_24\n\n\n\n\nQuarto Websites\n\n\nCharlotte Wickham, Emil Hvitfeldt\n\n\nBuild a website from scratch with Quarto. \n\n\nhttps://github.com/posit-conf-2024/quarto-websites\n\n\n\n\nR in Production\n\n\nHadley Wickham\n\n\nLearn how to write robust R code that both works reliably in production, and when it fails, is easy to debug. \n\n\nhttps://github.com/posit-conf-2024/r-in-production\n\n\n\n\nUsing Databricks with R\n\n\nEdgar Ruiz\n\n\nOverview of the latests methods to connect, and interact with Databricks services. \n\n\nhttps://posit-conf-2024.github.io/databricks\n\n\n\n\nWhat They Forgot To Teach You About R\n\n\nShannon Pileggi, E. David Aja\n\n\nThis workshop is designed to level up experienced R programmers in debugging and personal R administration. \n\n\nhttps://github.com/posit-conf-2024/wtf\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshops/dataviz.html",
    "href": "workshops/dataviz.html",
    "title": "Effective data visualization with ggplot2",
    "section": "",
    "text": "Description\nThe R programming language provides powerful primitives for data visualization. In particular, for many data scientists the package ggplot2 is the go-to toolkit for making visualizations. Through its modular and extensible design, ggplot2 has mushroomed into a formidable ecosystem, and with the aid of third-party extension packages there is little in terms of data visualization that cannot be done with ggplot2 these days. However, harnessing this flexibility and power can present a steep learning curve. While most users can quickly throw together a scatter plot or histogram, turning the initial figure draft into a carefully designed, publication-ready visualization requires a much deeper understanding of how ggplot2 functions.\nThis workshop has two complementary goals. First, you will learn useful tips and tricks for ggplot2 that will help you make plots that look stylish, unique, and exactly the way you want them to. This will include strategies for layering geoms, customizing coordinate systems and scales, tweaking the plot theme and other aspects of the plot appearance, and creating annotations. Second, you will learn some fundamental principles of figure design. These will include principles for choosing color palettes and for designing for color-vision deficiency, as well as some general principles of communication and design for accessibility.\n\n\nAudience\nThis course is for you if you:\n\nhave some prior experience with ggplot2 and the tidyverse\nwant to learn how to tweak and fine-tune plot designs in ggplot2\nwant to learn more about how to choose colors and how to design for accessibility\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nClaus Wilke is the Jane and Roland Blumberg Centennial Professor in Molecular Evolution at The University of Texas at Austin. Claus is a computational biologist and data scientist who performs research in the areas of protein and peptide biochemistry, microbiology, and generative AI. In addition, Claus teaches courses on data visualization at The University of Texas. He has published the book Fundamentals of Data Visualization, a book on how to effectively communicate with data. While the book itself is not about R programming, all visualizations in the book were made with R and ggplot2. Claus also has authored several popular R packages for data visualization, such as cowplot, ggridges, ggtext, and has made significant contributions to ggplot2 itself."
  },
  {
    "objectID": "workshops/tables.html",
    "href": "workshops/tables.html",
    "title": "Making Tables with gt and Great Tables",
    "section": "",
    "text": "Description\nThe gt package for R and the Great Tables package for Python both deal with an important element of written communication: tables. We don’t believe tables have to be drab or dull. Rather, we think that tables have the power to inspire and to excite!\nIn this workshop, you’ll learn about how to make tables that can accurately convey information yet look aesthetically pleasing. We will handle the first stumbling block: what do we even call the different parts of a table? After getting the table terminology down we’ll learn how to effectively assemble the table components and create powerful displays of information. We will start simply and progressively, working toward more complex table designs. Since there are two packages (one in R, one in Python) we will take a blended approach and learn about table generation in bilingual fashion.\nWe’ll cover the following:\n\nCreate table components and put them together (e.g., header, footer, stub, etc.)\nFormat cell values (numeric/scientific, date/datetime, etc.)\nRearranging columns and handling column value alignments\nStyling the table, either through data values or on a more granular level\nAdding icons, plots, images, and incorporating your own HTML\nmore!\n\n\n\nAudience\nThis course is for you if you:\n\nhave some basic working knowledge of either R or Python (separate sets of materials will be available for both R and Python),\nhave data you often need to present as data summaries\nwould like to level-up your ability to generate tables for publication\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nRichard Iannone (he/him) is a software engineer at Posit, PBC. He mainly works on open-source packages; here is a short list of packages that he is focused on: gt, Great Tables, and blastula.\n\n\n\n\nMichael Chow. Human memory, statistics, and computing."
  },
  {
    "objectID": "workshops/causal.html",
    "href": "workshops/causal.html",
    "title": "Causal Inference in R",
    "section": "",
    "text": "Description\nIn this workshop, we’ll teach the essential elements of answering causal questions in R through causal diagrams, and causal modeling techniques such as propensity scores and inverse probability weighting.\nIn both data science and academic research, prediction modeling is often not enough; to answer many questions, we need to approach them causally. In this workshop, we’ll teach the essential elements of answering causal questions in R through causal diagrams, and causal modeling techniques such as propensity scores and inverse probability weighting. We’ll also show that by distinguishing predictive models from causal models, we can better take advantage of both tools. You’ll be able to use the tools you already know–the tidyverse, regression models, and more–to answer the questions that are important to your work.\n\n\nAudience\nThis course is for you if you:\n\nknow how to fit a linear regression model in R,\nhave a basic understanding of data manipulation and visualization using tidyverse tools, and\nare interested in understanding the fundamentals behind how to move from estimating correlations to causal relationships.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nMalcolm Barrett is an epidemiologist and research software engineer at Stanford University. After receiving his Ph.D. in epidemiology from the University of Southern California, he worked as a data scientist at Apple and Posit. His work has focused on causal inference methodology and software development, including many R packages for causal inference.\n\n\n\n\n\n\n\n\n\nTravis Gerke, Sc.D., is Director of Data Science at the PCCTC, a contract research organization that facilitates clinical trials and real-world evidence studies in oncology. He is also co-founder and chief scientific officer of cStructure, a technology company built to empower teams with a collaborative causal design and inference platform."
  },
  {
    "objectID": "workshops/r_in_production.html",
    "href": "workshops/r_in_production.html",
    "title": "R in Production",
    "section": "",
    "text": "Description\nWhat it means to put R in production varies tremendously from organisation to organisation. However, I believe that there are common principles that you can learn to improve your code, regardless of the precise details of what production means for your organisation.\nThis workshop is organised around three big differences between running a local script on your computer and putting your code into production:\n\nNot just once: production code isn’t a one-off script; it runs repeatedly, and needs to run reliably even as the environment around it (e.g. R package versions and input data) changes. How can you ensure that code continues to run reliably months and years after you wrote it, and when there’s a problem it clearly reports on it.\nNot just your computer: production code doesn’t run on your computer. It typically runs on some other server where you can’t interactively experiment. This poses particular challenges for authentication and debugging.\nNot just you: the responsibility for production code is typically shared across a team. How can you ensure that you’re all working together as effectively as possible, sharing code and best practices, and continuing to get better at your job over time.\n\n\n\nAudience\nThis course is for you if you:\n\nGet frustrated debugging R code that’s running on another computer.\nStruggle keep your code running reliably as packages and data change over time.\nWant to generally improve the quality of your production code.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nHadley is Chief Scientist at Posit PBC, winner of the 2019 COPSS award, and a member of the R Foundation. He builds tools (both computational and cognitive) to make data science easier, faster, and more fun. His work includes packages for data science (like the tidyverse, which includes ggplot2, dplyr, and tidyr)and principled software development (e.g. roxygen2, testthat, and pkgdown). He is also a writer, educator, and speaker promoting the use of R for data science. Learn more on his website, http://hadley.nz."
  },
  {
    "objectID": "workshops/posit_tools_r.html",
    "href": "workshops/posit_tools_r.html",
    "title": "Data Science Workflows with Posit Tools — R Focus",
    "section": "",
    "text": "Description\nIn this R-focused workshop, we will discuss ways to improve your data science workflows! During the course, we will review packages for data validation, alerting, modeling, and more. We’ll use Posit’s open source and professional tools to string all the pieces together for an efficient workflow. We’ll discuss environments, managing deployed content, working with databases, and interoperability across data products.\n\n\nAudience\nThis course is for you if you:\n\nBuild finished data products starting from raw data and are looking to improve your workflow\nAre looking to expand your knowledge of Posit open source and professional tools\nWant to improve interoperability between data products in your work or on your team\nHave experience developing in R. An analogous course with a Python focus is also offered.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nRyan Johnson is a Data Science Advisor at Posit with a background in Microbiology and Bioinformatics. He obtained his PhD from the Uniformed Services University in Maryland and did his postdoctoral training at the National Human Genome Research Institute, NIH. The only thing that rivals his love for infectious diseases is generating ‘super cool’ visualizations from large data sets using R and RStudio. In his free time, you can find Ryan running marathons/ultramarathons in the DC area or hiking miles along the Appalachian Trail. Ryan resides in Gaithersburg with his wife and two feline co-workers.\n\n\n\n\nKatie Masiello is a Solutions Engineer at Posit. A mechanical engineer by training, she found her calling in data science while working statistical analysis in the aerospace industry. A good cup of coffee, reproducibility, and making life easier for the next user are three things she loves most. Katie is an avid knitter and knitr, and she can often be found trying to tame her ridiculously overgrown garden, collecting pebbles, or thinking about taking up running as a hobby."
  },
  {
    "objectID": "workshops/quarto_dashboards.html",
    "href": "workshops/quarto_dashboards.html",
    "title": "Build-a-Dashboard Workshop (with Quarto, R and/or Python)",
    "section": "",
    "text": "Description\nYou already analyze and summarize your data in computational notebooks with R and/or Python. What’s next? You can share your insights or allow others to make their own conclusions in eye-catching dasboards and straight-forward to author, design, and deploy Quarto Dashboards, regardless of the language of your data processing, visualization, analysis, etc. With Quarto Dashboards, you can create elegant and production-ready dashboards using a variety of components, including static graphics (ggplot2, Matplotlib, Seaborn, etc.), interactive widgets (Plotly, Leaflet, Jupyter Widgets, htmlwidgets, etc.), tabular data, value boxes, text annotations, and more. Additionally, with intelligent resizing of components, your Quarto Dashboards look great on devices of all sizes. And importantly, you can author Quarto Dashboards without leaving the comfort of your “home” – in plain text markdown with any text editor (VS Code, RStudio, Neovim, etc.) or any notebook editor (JupyterLab, etc.). This workshop will walk you through building an increasingly complex dashboard using various layout options and and deploy them as static web pages (with no special server required) as well as with a Shiny Server on the backend for enhanced interactivity.\n\n\nAudience\nThis course is for you if you:\n\ndo data analysis in computational notebooks\nshare your results with your audience in static or interactive dashboards\nwant to improve the design, user interface, and experience of your dashboards\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nDr. Mine Çetinkaya-Rundel (she/her) is Professor of the Practice at Duke University and Developer Educator at Posit. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine works on integrating computation into the undergraduate statistics curriculum, using reproducible research methodologies and analysis of real and complex datasets. Mine works on the OpenIntro project, whose mission is to make educational products that are free, transparent, and lower barriers to education. As part of this project she co-authored four open-source introductory statistics textbooks. She is also the creator and maintainer of datasciencebox.org and she teaches the popular Statistics with R MOOC on Coursera. Mine is a Fellow of the ASA and Elected Member of the ISI as well as the winner of the 2021 Robert V. Hogg Award for Excellence in Teaching Introductory Statistics."
  },
  {
    "objectID": "workshops/quarto_intro.html",
    "href": "workshops/quarto_intro.html",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "Description\nThis workshop will prepare you to author a rich array of documents in Quarto, the next generation of R Markdown. Quarto is an open-source scientific and technical publishing system that offers multilingual programming language support to create dynamic and static documents, books, presentations, blogs, and other online resources.\nThe focus for this workshop will be on single documents. You will learn to create static documents, to add interactivity to them with Shiny and htmlwidgets, or steer them in the direction of sophisticated scientific documents. In the afternoon you’ll take the same authoring approaches to create slide presentations in various formats such as reveal.js, beamer, and pptx.\n\n\nAudience\nThis course is for you if you:\n\nhave a basic knowledge of how to use the RStudio IDE,\nhave some familiarity with markdown, or\nare excited to author flexible single documents like technical reports and slide presentations.\n\nSeasoned users of R Markdown will get more out of the Build-a-Dashboard or Quarto Websites workshops, which are focused specific output types.\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nAndrew Bray is an Associate Teaching Professor in the Department of Statistics at UC Berkeley where he develops and teaches courses in statistics and data science. His research interests include statistical computing, data privacy, and applications of statistical models to solve real world problems. He was previously an Associate Professor of Statistics in the Department of Mathematics at Reed College and an NSF Five Colleges postdoctoral fellow in western Massachusetts."
  },
  {
    "objectID": "workshops/databricks.html",
    "href": "workshops/databricks.html",
    "title": "Using Databricks with R",
    "section": "",
    "text": "Description\nAs most organization’s data migrate to the cloud, the ability to analyze data in-place becomes more important. This workshop will walk you through how to think about remote data, how to access it, and how to analyze it efficiently. We will review the latest in integrations between R and Databricks. The two integrations that we will review are:\n\nSpark via Databricks Connect\nODBC connection\n\nDuring the workshop, we will discuss best practices for when to use which integration, as well as techniques to take your analysis into production.\n\n\nAudience\nThis course is for you if you:\n\nAre an R user\nPlan, or are currently, using Databricks services\nNeed to learn how to access and analyze data in Databricks\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nEdgar co-authored a book called “Mastering Spark with R,” and is currently the maintainer of the sparklyr package. Edgar has also authored multiple articles, blog posts sharing analytics insights, and server infrastructure for data science. He has a background in deploying enterprise reporting, and business intelligence solutions.\nhttps://www.linkedin.com/in/edgararuiz/"
  },
  {
    "objectID": "workshops/programming_r.html",
    "href": "workshops/programming_r.html",
    "title": "From R User to R Programmer",
    "section": "",
    "text": "Description\nThis is a one-day, hands-on workshop intermediate R users who use the tidyverse and want to improve and reduce the amount of duplication in their code. You will learn the two main ways to reduce duplication: creating functions and using iteration.\nWe will use a tidyverse approach to cover function design and iteration. When writing a function you will learn how to deal with “data masking”, give default values to arguments, give unspecified arguments, and what side effects are and how to manage them. In the afternoon, you will learn how to iterate across the columns of a dataframe using across(), what “anonymous” functions are and how to read and write multiple files using purrr.\n\n\nAudience\nThis course is for you if you:\n\nhave experience equivalent to an introductory data science course using tidyverse\nfeel comfortable with the Whole game part of R for Data Science\nwant to learn how to write functions and use iteration to reduce duplication in your code\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nEmma Rand is a Senior Lecturer in the Department of Biology at the University of York where she specializes in teaching data science and reproducibility, particularly to those who do not see themselves as programmers. She leads a UKRI funded project called Cloud-SPAN which trains researchers in cloud-based high performance computing for ’omics. She is a Software Sustainability Institute Fellow, a Teaching team lead for R Forwards and delivers data science training for the Royal Society of Biology and the Biochemical Society.\n\n\n\n\nIan Lyttle is a Data Scientist at Schneider Electric. His technical interests include visualization, interactivity, and functional programming. He is a community contributor to tidyverse and r-lib, and maintains CRAN packages including vegawidget and boxr. He has delivered tutorials on a variety of R topics at UseR!, Uncoast Unconf, and the Iowa State University Graphics Group."
  },
  {
    "objectID": "workshops/pharmaverse.html",
    "href": "workshops/pharmaverse.html",
    "title": "Flavors of the pharmaverse",
    "section": "",
    "text": "Description\nOver the past 4 years, the pharmaverse was created and has blossomed into a booming community of organizations and package developers aimed at supporting R development with focus on the clinical reporting pipeline. Even within a world as standardized as regulatory submissions, organizations still tend to have sometimes vastly different requirements within their own processes.\nIn this workshop, we’ll give a high level overview of the scope and tools available within the pharmaverse for the clinical pipeline, including tools for ADaM data set curation, creating Analysis Results Data Sets, and TLGs. To help attendees understand how there are different paradigms and pathways through the pharmaverse, we’ll take a tour through two to three different strategies available to support table, listing, and figure creation. Attendees of this workshop will walk away with an understanding of how the pharmaverse can help their organization and where they can look to learn more about the right tools to support their needs.\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nDaniel D. Sjoberg (he/him) is a Senior Principal Data Scientist at Genentech. Previously, he was a Lead Data Science Manager at the Prostate Cancer Clinical Trials Consortium, and a Senior Biostatistician at Memorial Sloan Kettering Cancer Center in New York City. He enjoys R package development, creating many packages available on CRAN, R-Universe, and GitHub. He’s a co-organizer of rainbowR (a community that supports, promotes and connects LGBTQ+ people who code in the R language) and of the R Medicine Conference. His research interests include adaptive methods in clinical trials, precision medicine, and predictive modeling. Daniel is the winner of the 2021 American Statistical Association (ASA) Innovation in Statistical Programming and Analytics award.\n\n\n\n\nBecca Krouse is a data scientist in GSK’s Statistics and Data Science Innovation Hub. A biostatistician by training, she has experience spanning 13+ years in the field of clinical research and specializes in developing R-based tools.\n\n\n\n\nEllis Hughes is a Data Science Leader and has worked in the pharmaceutical industry for almost a decade. He focuses on how organizations can use R and take open source approaches to improve processes and solve problems. During his free time he organizes the Seattle UseR group, the Cascadia R Conference, and hosts a weekly R screencast, TidyX, to explain data science concepts.\n\n\n\n\nAndrew Bates Andrew is a Data Solutions Engineer at Atorus Research where he builds tools that enable people to solve their data problems. He specializes in R and its intersection with web technologies.\n\n\n\n\nCasey Aguilar-Gervase is a Senior Data Visualization Engineer at Atorus. Casey enjoys combining the art of design with clinical programming in R to create innovative Shiny applications. With a strong background in both disciplines, Casey is passionate about pushing the boundaries of Shiny to develop user-friendly, data-driven solutions that meet technical requirements and provide an exceptional user experience."
  },
  {
    "objectID": "workshops/shiny_r_intro.html",
    "href": "workshops/shiny_r_intro.html",
    "title": "Introduction to Shiny for R",
    "section": "",
    "text": "Description\nShiny is an R package that makes it easy to build interactive web apps straight from R. This workshop will start at the beginning: designing and creating user interfaces, learning and mastering the reactive model that connects your R code to the interface, and deploying apps publicly and privately. We will wrap up with some intermediate-level tools: debugging and modularizing your apps and implementing dynamic user interfaces. In the end, you’ll be a confident Shiny user, able to design interactive apps to achieve your purpose and produce a polished and professional implementation.\n\n\nAudience\nThis workshop is for you if you:\n\nare comfortable with the basics of R, such as writing functions, indexing vectors and lists, debugging simple errors, and working with data structures like data frames,\nare interested in creating interactive web applications, and\nhave no or minimal experience with Shiny for R. If you have a bit of experience, you’ll see things in a new way. If you don’t, we’ll get you started on the right footing.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nColin Rundel is Associate Professor of the Practice at Duke University in the department of Statistical Science where he has been teaching since 2012. His work focuses on teaching statistical computing to both undergraduate and graduate students in both R and Python. He has been teaching and using Shiny since 2015."
  },
  {
    "objectID": "workshops/arrow.html",
    "href": "workshops/arrow.html",
    "title": "Big Data in R with Arrow",
    "section": "",
    "text": "Description\nData analysis pipelines with larger-than-memory data are becoming more and more commonplace. In this workshop you will be introduced to Apache Arrow, a multi-language toolbox for working with larger-than-memory tabular data, to create seamless “big” data analysis pipelines with R.\nThis workshop will focus on using the the arrow R package—a mature R interface to Apache Arrow—to process larger-than-memory files and multi-file data sets with arrow using familiar dplyr syntax. You’ll learn to create and use the interoperable data file format Parquet for efficient data storage and access, with data stored both on disk and in the cloud, and also how to exercise fine control over data types to avoid common large data pipeline problems. Designed for new-to-arrow R users, this workshop will provide a foundation for using Arrow, giving you access to a powerful suite of tools for performant analysis of larger-than-memory tabular data in R.\n\n\nAudience\nThis course is for you if you:\n\nwant to learn how to work with tabular data that is too large to fit in memory using existing R and tidyverse syntax implemented in Arrow\nwant to learn about Parquet, a powerful file format alternative to CSV files\nwant to learn how to engineer your tabular data storage for more performant access and analysis with Apache Arrow\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nNic Crane is an R consultant with a background in data science and software engineering. They are passionate about open source, and learning and teaching all things R. Nic is part of the core team that maintain the Arrow R package, and a co-author of “Scaling up with R and Arrow”, due to be published by CRC Press later this year.\n\n\n\n\nSteph Hazlitt is a data scientist, researcher and R enthusiast. She has spent the better part of her career wrangling data with R and supporting people and teams in creating and sharing data science-related products and open source software. Steph is the Director of Data Science Partnerships with BC Stats."
  },
  {
    "objectID": "workshops/tidymodels_advanced.html",
    "href": "workshops/tidymodels_advanced.html",
    "title": "Advanced Tidymodels",
    "section": "",
    "text": "Description\nIn this workshop you will learn more about model optimization using the tune and finetune packages, including racing and iterative methods. You’ll be able to do more sophisticated feature engineering with recipes.\nTime permitting, model ensembles via stacking will be introduced.\nThis course is focused on the analysis of tabular data and does not include deep learning methods.\n\n\nAudience\nThis workshop is for you if you:\n\nhave used tidymodels packages like recipes, rsample, and parsnip.\nare comfortable with tidyverse syntax (e.g. piping, mutates, pivoting), and\nhave some experience with resampling and modeling (e.g., linear regression, random forests, etc.), but we don’t expect you to be an expert in these.\n\nParticipants who are new to tidymodels will benefit from taking the Introduction to tidymodels workshop before joining this one.\n\n\nInstructor\n\n\n\n\n\n\n\n\n\n\nMax Kuhn is a software engineer at Posit. He is responsible for the tidymodels ecosystem and maintains about 30 packages, including caret. He was applying models in the pharmaceutical and diagnostic industries for over 18 years. Max has a Ph.D. in Biostatistics. He, and Kjell Johnson, wrote the book Applied Predictive Modeling, which won the Ziegel award from the American Statistical Association. Their second book, Feature Engineering and Selection, was published in 2019 and the book Tidy Models with R was published in 2022. He is currently working on Applied Machine Learning for Tabular Data"
  },
  {
    "objectID": "workshops/posit_tools_python.html",
    "href": "workshops/posit_tools_python.html",
    "title": "Data Science Workflows with Posit Tools — Python Focus",
    "section": "",
    "text": "Description\nThis Python-focused workshop will discuss ways to improve your data science workflows! During the course, we will review packages for data validation, alerting, modelling, and more. We’ll use Posit’s open-source and professional tools to string all the pieces together for an efficient workflow. We’ll discuss environments, managing deployed content, working with databases, and interoperability across data products.\n\n\nAudience\nThis course is for you if you:\n\nBuild finished data products starting from raw data and are looking to improve your workflow\nAre looking to expand your knowledge of Posit open source and professional tools\nWant to improve interoperability between data products in your work or on your team\nHave experience developing in Python. An analogous course with an R focus is also offered\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nSam Edwardes is obsessed with data science, R, Python, and all things open source. As a Solutions Engineer at Posit, he loves getting into the nitty gritty and optimizing everything. When he is not tinkering on his computer, you can find Sam and his dog Roo on adventures in beautiful British Columbia.\n\n\n\n\nGagandeep Singh is a former software engineer and data scientist who has worked in a variety of cross-technology teams. Before joining Posit as a Solutions Engineer, he consulted with Fortune 500 companies to build their analytical capacities. Outside of work, you can find him at a local bookstore."
  },
  {
    "objectID": "workshops/wtf.html",
    "href": "workshops/wtf.html",
    "title": "What They Forgot To Teach You About R",
    "section": "",
    "text": "Description\nThis 1 day What They Forgot (WTF) To Teach You About R workshop is for experienced R and RStudio users who want to better understand R execution via debugging and personal R administration. At the conclusion of the workshop you will have distinct strategies for debugging your own code versus someone else’s code, as well as strategies for maintaining your R installation through the lens of reproducibility.\n\n\nAudience\nThis course is for you if you:\n\nHave you been using R for a while and you want a deeper understanding of what code is executing when and where it is coming from.\nWant strategies for overcoming roadblocks when when all else has failed in function execution or package installation.\nAre willing to get into the weeds of your R installation, project organization, error messages, and source code.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nE. David Aja is a Solutions Engineer at Posit. Before joining Posit, he worked as a data scientist in the public sector.\n\n\n\n\nShannon Pileggi (she/her) is a Lead Data Scientist at The Prostate Cancer Clinical Trials Consortium, an occasional blogger, and a member of the R-Ladies Global leadership team. She enjoys automating data wrangling and data outputs, and making both data insights and learning new material digestible."
  },
  {
    "objectID": "workshops/tidymodels_intro.html",
    "href": "workshops/tidymodels_intro.html",
    "title": "Introduction to tidymodels",
    "section": "",
    "text": "Description\nThis workshop will teach you core tidymodels packages and their uses: data splitting/resampling with rsample, model fitting with parsnip, measuring model performance with yardstick, and basic pre-processing with recipes. Time permitting, you’ll be introduced to model optimization using the tune package. You’ll learn tidymodels syntax as well as the process of predictive modeling for tabular data.\n\n\nAudience\nThis workshop is for you if you:\n\nare comfortable using tidyverse packages to read data into R, transform and reshape data, and make a variety of graphs, and\nhave had some exposure to basic statistical concepts such as linear models, residuals, etc.\n\nIntermediate or expert familiarity with modeling or machine learning is not required. Interested students who have intermediate or expert familiarity with modeling or machine learning may be interested in the Advanced tidymodels workshop.\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nHannah Frick is a software engineer and statistician on the tidymodels team at Posit. She holds a PhD in statistics and has worked in data science consultancy as well as interdisciplinary research at University College London in cooperation with Team GB Hockey.\n\n\n\n\nSimon Couch works on software for statistical modeling on the tidymodels team at Posit. With a background in statistics and sociology, Simon is passionate about free and open source software and data pedagogy. He is an author and maintainer of several R packages, including the stacks package, which was awarded the 2021 John M. Chambers Statistical Software Award."
  },
  {
    "objectID": "workshops/pkg_dev.html",
    "href": "workshops/pkg_dev.html",
    "title": "Package Development: The Rest of the Owl",
    "section": "",
    "text": "Description\nIn R, the fundamental unit of reusable and shareable code is a package, containing helpful functions, documentation, and sometimes sample data. Putting R code in a package is the best way to share our code with others or to share code across different projects.\nThis workshop assumes you’ve already dipped your toe in package development, i.e. that you’ve managed to create a basic package and pass R CMD check. In terms of “How to draw an owl”, you’ve definitely drawn some circles. But now it’s time to draw the rest of the owl!\n\nYou will learn workflows and skills that are (a) very important for package development and (b) very different from writing R scripts. We will lean heavily on the tools and principles used by the tidyverse team, embodied in the devtools family of packages, including usethis, testthat, and roxygen2.\nThe exact topics won’t be finalized until closer to conf, but they are likely to be drawn from this list:\n\nFundamental daily workflows: devtools::load_all() and check()\nDocumentation: function documentation, vignettes, and website\nDependencies and namespaces: how to use other packages in yours and how to distinguish the parts of your package that are internal vs. external\nTesting: the testthat package and the philosophy of writing tests as you go (vs. “later”)\nDebugging: beyond print statements\nData: internal data vs. data available to your user\n\nIt is likely we will reserve a chunk of time late in the day for you to apply something you’ve learned to your own package(s). This is a good chance to talk things through with members of the tidyverse team.\nThis will be an interactive 1-day workshop, and we will be using the RStudio IDE to work through the materials.\n\n\nAudience\nThis course is for you if you:\n\nAre very comfortable writing R scripts and functions.\nHave already created a basic package, e.g., you’ve successfully worked through The Whole Game chapter from R Packages or have equivalent experience.\nHave concrete plans for one or more specific packages you want to create. You might have even started implementing these plans.\nAre interested in using devtools/RStudio for package development.\nAre at least curious about Git/GitHub. We won’t have time to teach this explicitly, but you will certainly see Git/GitHub through out the day.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nJenny is a software engineer at Posit, usually working on the tidyverse packages or its supporting ecosystem, and is a member of the R Foundation. She recently co-authored the second edition of the R Packages book and is the maintainer of the devtools and usethis packages (among others)."
  },
  {
    "objectID": "workshops/ml_python.html",
    "href": "workshops/ml_python.html",
    "title": "Introduction to machine learning in Python with Scikit-learn",
    "section": "",
    "text": "Description\nThis workshop will teach you how to perform machine learning for prediction in Python using the widely-used Scikit-learn learn package. You will be introduced to best practices for machine learning model creation and selection, including data splitting, pre-processing, parameter and model optimization, as well as results visualization and communication. Workshop examples will begin with simple, intuitive models (e.g., K-nearest neighbors, linear regression) but also demonstrate the use of more commonly used and industry standard models (e.g., L1 Regularized regression and Light Gradient Boosting Machines). The workshop will focus on demonstrating how to do this using the modern Scikit-learn pipeline syntax.\n\n\nAudience\nThis course is for you if you:\n\nare comfortable using Python and the pandas and package to read, transform and reshape data\nhave experience making a variety of graphs with any Python package.\n\nIntermediate or expert familiarity with modeling or machine learning is not required.\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nTiffany Timbers is an Associate Professor of Teaching in the Department of Statistics and Co-Director for the Master of Data Science program (Vancouver Option) at the University of British Columbia. In these roles she teaches and develops curriculum around the responsible application of Data Science to solve real-world problems. One of her favorite courses she teaches is a graduate course on collaborative software development, which focuses on teaching how to create R and Python packages using modern tools and workflows. She is an author of Data Science: A First Introduction - a textbook that serves as an approachable introduction to the world of data science, written now in both R and Python.\n\n\n\n\nTrevor Campbell is an Associate Professor in the Department of Statistics at the University of British Columbia. His research focuses on automated, scalable Bayesian inference algorithms, Bayesian nonparametrics, streaming data, and Bayesian theory. He was previously a postdoctoral associate advised by Tamara Broderick in the Computer Science and Artificial Intelligence Laboratory (CSAIL) and Institute for Data, Systems, and Society (IDSS) at MIT, a Ph.D. candidate under Jonathan How in the Laboratory for Information and Decision Systems (LIDS) at MIT, and before that he was in the Engineering Science program at the University of Toronto. He is an author of Data Science: A First Introduction - a textbook that serves as an approachable introduction to the world of data science, written now in both R and Python."
  },
  {
    "objectID": "workshops/quarto_websites.html",
    "href": "workshops/quarto_websites.html",
    "title": "Quarto Websites",
    "section": "",
    "text": "Description\nDo you need a professional website to showcase your work? Or have you got an idea for a website at work, but it needs to reflect your organization’s brand? If you’ve used Quarto to produce a document, you’ve already got the technical skills to create a Quarto website. In this workshop, you’ll learn everything else you need to build a website and customize its appearance.\nYou’ll get a running start by using a template we’ve designed to be functional and attractive, but also act as a guide for your learning. Then you’ll:\n\nAdd pages and navigation, and learn best practices for structuring your content.\nCustomize the visual appearance of your site by mastering the basics of SCSS and CSS and how they apply to Quarto websites.\nUse listings, a special kind of page, to showcase related content like blog posts, projects, or talks.\n\nBy the end of the workshop you’ll have built and published (if you want) a personal website, but the same tools and techniques will apply to any kind of website you might like to build.\nWe’ll assume you’ve used Quarto to produce documents, but we won’t assume you have any HTML, CSS/SCSS or Git/GitHub experience, nor will we assume any particular programming language (R, Python etc.) or level of programming experience.\n\n\nAudience\nThis course is for you if you:\n\nHave used Quarto to generate documents (e.g. HTML, PDF, MS Word etc.)\nAre comfortable editing plain text documents (e.g .qmd) in your IDE (e.g. RStudio, Visual Studio Code etc.)\nWant to walk away with your own personal website\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nDr. Charlotte Wickham (she/her) is a Developer Educator on the Quarto team at Posit. As part of her job at Posit, Charlotte helps to keep quarto.org—a website about, and also built with, Quarto—up to date. Prior to Posit, she taught Statistics and Data Science at Oregon State University where she received awards for her in-person and online teaching.\n\n\n\n\nEmil Hvitfeldt (he/him) is a Software Engineer on the tidymodels team at Posit. Emil works on making modeling easy and intuitive with tidy tools. Outside of modeling, he is also trying to make slidecrafting a well respecting verb."
  },
  {
    "objectID": "workshops/intro_ds_python.html",
    "href": "workshops/intro_ds_python.html",
    "title": "Introduction to Data Science with Python",
    "section": "",
    "text": "Description\nThis is not a standard workshop, but a six-week online apprenticeship that culminates in-person at posit::conf(2024).\nHere, you will learn the foundations of Python for data science under the guidance of a Posit Academy mentor and in the company of a close group of fellow learners. You will be expected to complete a weekly curriculum of interactive tutorials, and to attend a weekly presentation meeting with your mentor and fellow learners. Topics will include importing packages and datasets, visualizing data with plotnine, wrangling data with pandas, and reporting reproducibly with Quarto.\nNo prior knowledge of Python required. Visit posit.co/academy to learn more about this uniquely effective learning format.\n\n\n\n\n\n\nImportant dates\n\n\n\n🗓️ Online sessions begin the week of July 1st, 2024.\n🚫 Registration for this workshop will close on June 24th, 2024.\n\n\n\n\nAudience\nThis course is for you if you:\n\nare new to Python,\nhave dabbled in Python, but are not sure how to use Python to do data science, or\nare an R user who wants to work more closely with Python users on your team.\n\n\n\nInstructors\n\n\n\n\n\n\n\n\n\n\nPosit Academy is Posit’s internal team of data scientists and educators. We provide a cohort-based, mentor-led, hands-on data science apprenticeship for working professionals. It is delivered on an online platform with interactive coding exercises and frequent cross-learner collaboration."
  },
  {
    "objectID": "workshops/shiny_r_level_up.html",
    "href": "workshops/shiny_r_level_up.html",
    "title": "Level Up with Shiny for R",
    "section": "",
    "text": "Description\nShiny, a web framework for R and Python, lets you quickly create rich, data-driven web applications for yourself, your clients, your students, or your colleagues. This workshop will give you the skills you need to build complex applications with brilliant user interfaces. You’ll learn how to make the most of recent developments in the Shiny ecosystem, while mastering techniques for modularizing and structuring your applications for scalability and maintainability. Along the way, you’ll encounter new techniques to speed up your applications using caching and databases for a smooth user experience.\n\n\nAudience\nThis workshop is for you if\n\nYou can comfortably create a basic Shiny for R application, but are ready to make apps that are a little more complicated.\nYou’ve made a Shiny application that has started to grow in terms of users or lines of code and you want to improve your user interface or your code structure to support your growing app.\nYou want to bring advanced Shiny tools like modules, caching, databases and testing into your app building workflows.\nYou have (or want to put) a Shiny app into production. You also know that in production means that someone depends on the app and that that someone could even be you, a small handful of your colleagues, or an entire division of your organization.\n\n\n\nInstructor\n\n\n\n\n\n\n\n\n\n\nGarrick Aden-Buie is a software engineer for Shiny at Posit. He is passionate about building broadly accessible tools for data scientists in R and Python. Before joining the Shiny team, he helped build Posit Academy, an online, immersive, data science apprenticeship for professional teams. Garrick has been using and teaching Shiny since 2014, and he shares his experience and projects on his website at garrickadenbuie.com."
  },
  {
    "objectID": "workshops/shiny_python_intro.html",
    "href": "workshops/shiny_python_intro.html",
    "title": "Introduction to Shiny for Python",
    "section": "",
    "text": "Description\nShiny for Python is a new framework for building performant, beautiful web applications in Python. In this one-day workshop, you will learn the basic building blocks of a Shiny application which will let you create both quick, simple applications and elaborate mission-critical ones.\nIn particular this workshop covers:\n\nThe basics of building a Shiny for Python app\nWhen to use reactive calculations and reactive effects\nHow modules can help you develop reusable components\nTheming and deploying your application\n\nAt the end of this course you will be able to:\n\nBuild a Shiny app in Python\nArticulate how Shiny differs from other frameworks\nUtilize best practices to make sure your app is robust and scalable\n\n\n\nAudience\nThis course is for you if you are:\n\nA Python programmer interested in quickly building efficient web applications\nAn educator interested in integration Shiny apps into your python course\nAn R programmer interested in building Shiny apps in Python\n\n\n\nFAQ\n\nWhat if I’m a complete beginner?\n\nYou should have a basic understanding of Python and be able to install packages with pip, do basic data manipulation, and draw plots.\n\nWhat if I’ve never built a Shiny app before?\n\nThis workshops doesn’t require any Shiny or web application experience. We will start from scratch to build simple applications before moving on to more complex ones.\n\nWhy should I learn Shiny if I already know Streamlit or Dash?\n\nWe believe that Shiny is the best framework for building data applications in Python. It’s reactive execution model means that you can build performant applications without explicitly caching data or managing application state. See this blog post for more on why we think that Shiny is worth learning.\n\nI’m an expert with Shiny for R, is this workshop for me?\n\nThe R and Python Shiny packages are quite similar, so some of the content in this workshop may be familiar to you. That said it’s a great opportunity to fill in missing pieces and ask question about Python best practices. Check out our quickstart guide for R users and this tutorial if you want to quickly get up to speed with Shiny for Python.\n\n\nInstructors\n\n\n\n\n\n\n\n\n\n\nGarrett is Director of Education at Posit PBC. He is a contributor to the Shiny for Python website, and the co-author of several data science books including, R for Data Science. |\n\n\n\n\nAndrie is Director of Product Strategy at Posit. He started using R in 2009 for market research statistics and joined Revolution Analytics in 2013, assisting customers with their adoption of R for machine learning. After the acquisition of Revolution analytics by Microsoft in 2015, he implemented deep learning and machine learning projects in the Azure cloud."
  },
  {
    "objectID": "workshops/dev_ops.html",
    "href": "workshops/dev_ops.html",
    "title": "DevOps for Data Scientists",
    "section": "",
    "text": "Description\nIn this course we will learn the key principles of DevOps and problems which it intends to solve for data scientists. We will discuss how DevOps practices such as CI/CD enhance collaboration, automation, and reproducibility. We will learn common workflows for environment management, package management, containerization, monitoring & logging, and version control. Participants will get hands-on experience with a variety of tools including Docker, Github Actions, and APIs. Posit Pro Products will also be used by participants to quickly create and deploy R or python code using DevOps pipelines.\nPlease note that this course is not prescriptive around DevOps tools which are constantly growing and changing. Given that, the exact tools that will be used in this course (e.g. Jenkins, Azure Devops, etc) are subject to change.\n\n\nAudience\nThis course is for you if you:\n\nWant to learn the main principles and tools of DevOps\nAre a data scientist who wants to put their R/Python code into production or work more closely with DevOps teams\nWant to get hands-on experience using docker, CI/CD tools, and other DevOps workflows.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nRika Gorn is a Senior Solutions Engineer at Posit where she helps customers and organizations create infrastructure for data analytics and data science. Her background is in data science and data engineering."
  },
  {
    "objectID": "workshops/intro_ds_r.html",
    "href": "workshops/intro_ds_r.html",
    "title": "Introduction to Data Science with R and Tidyverse",
    "section": "",
    "text": "Description\nThis is not a standard workshop, but a six-week online apprenticeship that culminates in-person at posit::conf(2024).\nHere, you will learn the foundations of R and the Tidyverse under the guidance of a Posit Academy mentor and in the company of a close group of fellow learners. You will be expected to complete a weekly curriculum of interactive tutorials, and to attend a weekly presentation meeting with your mentor and fellow learners. Topics will include the basics of R, importing, visualizing and wrangling data with the tidyverse, and reporting reproducibly with Quarto.\nNo prior knowledge of R required. Visit posit.co/academy to learn more about this uniquely effective learning format.\n\n\n\n\n\n\nImportant dates\n\n\n\n🗓️ Online sessions begin the week of July 1st, 2024.\n🚫 Registration for this workshop will close on June 24th, 2024.\n\n\n\n\nAudience\nThis course is for you if you:\n\nare new to R or the Tidyverse,\nhave dabbled in R, but now want a rigorous foundation in up-to-date data science best practices, or\nare a SAS or Excel user looking to switch your workflows to R.\n\n\n\nInstructors\n\n\n\n\n\n\n\n\n\n\nPosit Academy is Posit’s internal team of data scientists and educators. We provide a cohort-based, mentor-led, hands-on data science apprenticeship for working professionals. It is delivered on an online platform with interactive coding exercises and frequent cross-learner collaboration."
  },
  {
    "objectID": "workshops/databases.html",
    "href": "workshops/databases.html",
    "title": "Databases with R",
    "section": "",
    "text": "Description\nAs a data professional, you likely have to deal with databases that are larger than your available RAM. Downloading the data requires patience, applying traditional workflows is frustrating. This workshop will teach you to work with your (large) data:\n\nif it resides in a traditional database, effortlessly\nfrom local storage, using DuckDB, a modern database engine tailored to data analysis\n\nThe workshop will introduce basic database concepts and move on with practical work with traditional databases and DuckDB. You are encouraged to bring your own data(base) to immediately apply what you have learned during the workshop. Among others, the workshop showcases the DBI, dbplyr, duckdb, duckplyr, and dm packages.\n\n\nAudience\nThis course is for you if you:\n\nhave worked with the dplyr package.\nhave just read or heard about databases and are ready to get your hands dirty.\nperformed basic operations on a database, and you would like to deepen your knowledge.\nhave heard about DuckDB and want to know what makes it unique and how to leverage it in your daily workflow.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nKirill Müller has been working on the boundary between data and computer science for more than 25 years. He has been awarded five R consortium projects to improve database connectivity and performance in R. Kirill is a core contributor to several tidyverse packages, including dplyr and tibble, and is currently working on duckplyr, the next iteration of dplyr that uses DuckDB as a backend. He holds a Ph.D. in Civil Engineering from ETH Zurich and is a founder and partner at cynkra."
  },
  {
    "objectID": "workshops/vetiver.html",
    "href": "workshops/vetiver.html",
    "title": "Intro to MLOps with vetiver",
    "section": "",
    "text": "Description\nData scientists understand what goes into training a machine learning or statistical model, but bringing that model into a production environment can be daunting.\nThis workshop will cover the fundamentals of MLOps (machine learning operations), the practices used to create a MLOps strategy, and what kinds of tasks and components are involved. We’ll use vetiver, a framework for MLOps tasks in Python and R, to version, deploy, and monitor the models you have trained and want to deploy and maintain in production reliably and efficiently.\n\n\nAudience\nWe expect participants to have exposure to basic modeling and machine learning practice, but NOT expert familiarity with advanced ML or MLOps topics.\nThis workshop is for you if you:\n\nhave intermediate R or Python knowledge (this will be a “choose your own adventure” workshop where you can work through the exercises in either R or Python),\ncan read data from CSV and other flat files, transform and reshape data, and make a wide variety of graphs, and\ncan fit a model to data with your modeling framework of choice.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nIsabel Zimmerman(she/her) is a software engineer at Posit, PBC. As part of her job at Posit, she builds and maintains MLOps Python packages such as vetiver and pins. She has a background as a software engineer/data scientist working with data and models in cloud environments.\n\n\n\n\nJulia Silge is a data scientist and software engineer at Posit PBC where she works on open source modeling and MLOps tools. She is an author, an international keynote speaker, and a real-world practitioner focusing on data analysis and machine learning.Julia loves text analysis, making beautiful charts, and communicating about technical topics with diverse audiences."
  }
]