[
  {
    "objectID": "workshops/dataviz.html",
    "href": "workshops/dataviz.html",
    "title": "Dataviz (Details TBD)",
    "section": "",
    "text": "Description\nFull workshop description goes here. Multi-paragraph ok.\n\n\nAudience\nThis course is for you if you:\n\nlist at least\nthree attributes\nfor your target audience\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nClaus Wilke is the Jane and Roland Blumberg Centennial Professor in Molecular Evolution at The University of Texas at Austin. He holds a PhD in Theoretical Physics from the University of Bochum in Germany, and he received postdoctoral training in biological physics in the lab of Chris Adami at Caltech. Claus Wilke has published extensively in the areas of computational biology, molecular evolution, protein biochemistry, and virology. He has also authored several popular R packages used for data visualization, such as cowplot, ggridges, and ggtext, and he is a regular contributor to the package ggplot2. In 2019, Wilke published the book Fundamentals of Data Visualization, which provides a concise introduction to effectively visualizing many different types of data sets."
  },
  {
    "objectID": "workshops/programming_r.html",
    "href": "workshops/programming_r.html",
    "title": "From R User to R Programmer",
    "section": "",
    "text": "Description\nThis is a one-day, hands-on workshop intermediate R users who use the tidyverse and want to improve and reduce the amount of duplication in their code. You will learn the two main ways to reduce duplication: creating functions and using iteration.\nWe will use a tidyverse approach to cover function design and iteration. When writing a function you will learn how to deal with “data masking”, give default values to arguments, give unspecified arguments, and what side effects are and how to manage them. In the afternoon, you will learn how to iterate across the columns of a dataframe using across(), what “anonymous” functions are and how to read and write multiple files using purrr.\n\n\nAudience\nThis course is for you if you:\n\nhave experience equivalent to an introductory data science course using tidyverse\nfeel comfortable with the Whole game part of R for Data Science\nwant to learn how to write functions and use iteration to reduce duplication in your code\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nEmma Rand is a Senior Lecturer in the Department of Biology at the University of York where she specializes in teaching data science and reproducibility, particularly to those who do not see themselves as programmers. She leads a UKRI funded project called Cloud-SPAN which trains researchers in cloud-based high performance computing for ’omics. She is a Software Sustainability Institute Fellow, a Teaching team lead for R Forwards and delivers data science training for the Royal Society of Biology and the Biochemical Society.\n\n\n\n\nIan Lyttle is a Data Scientist at Schneider Electric. His technical interests include visualization, interactivity, and functional programming. He is a community contributor to tidyverse and r-lib, and maintains CRAN packages including vegawidget and boxr. He has delivered tutorials on a variety of R topics at UseR!, Uncoast Unconf, and the Iowa State University Graphics Group."
  },
  {
    "objectID": "workshops/shiny_r_intro.html",
    "href": "workshops/shiny_r_intro.html",
    "title": "Introduction to Shiny for R",
    "section": "",
    "text": "Description\nShiny is an R package that makes it easy to build interactive web apps straight from R. This workshop will start at the beginning: designing and creating user interfaces, learning and mastering the reactive model that connects your R code to the interface, and deploying apps publicly and privately. We will wrap up with some intermediate-level tools: debugging and modularizing your apps and implementing dynamic user interfaces. In the end, you’ll be a confident Shiny user, able to design interactive apps to achieve your purpose and produce a polished and professional implementation.\n\n\nAudience\nThis workshop is for you if you:\n\nare comfortable with the basics of R, such as writing functions, indexing vectors and lists, debugging simple errors, and working with data structures like data frames,\nare interested in creating interactive web applications, and\nhave no or minimal experience with Shiny for R. If you have a bit of experience, you’ll see things in a new way. If you don’t, we’ll get you started on the right footing.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nColin Rundel is Associate Professor of the Practice at Duke University in the department of Statistical Science where he has been teaching since 2012. His work focuses on teaching statistical computing to both undergraduate and graduate students in both R and Python. He has been teaching and using Shiny since 2015."
  },
  {
    "objectID": "workshops/wtf.html",
    "href": "workshops/wtf.html",
    "title": "What They Forgot To Teach You About R",
    "section": "",
    "text": "Description\nThis 1 day What They Forgot (WTF) To Teach You About R workshop is for experienced R and RStudio users who want to better understand R execution via debugging and personal R administration. At the conclusion of the workshop you will have distinct strategies for debugging your own code versus someone else’s code, as well as strategies for maintaining your R installation through the lens of reproducibility.\n\n\nAudience\nThis course is for you if you:\n\nHave you been using R for a while and you want a deeper understanding of what code is executing when and where it is coming from.\nWant strategies for overcoming roadblocks when when all else has failed in function execution or package installation.\nAre willing to get into the weeds of your R installation, project organization, error messages, and source code.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nE. David Aja is a Solutions Engineer at Posit. Before joining Posit, he worked as a data scientist in the public sector.\n\n\n\n\nShannon Pileggi (she/her) is a Lead Data Scientist at The Prostate Cancer Clinical Trials Consortium, an occasional blogger, and a member of the R-Ladies Global leadership team. She enjoys automating data wrangling and data outputs, and making both data insights and learning new material digestible."
  },
  {
    "objectID": "workshops/shiny_python_adv.html",
    "href": "workshops/shiny_python_adv.html",
    "title": "Advanced Shiny for Python",
    "section": "",
    "text": "Description\nOur Intro to Shiny for Python workshop takes you through the basics of building Shiny for Python applications with Shiny Express. This course builds on the concepts from the introductory course and teaches you how to build and maintain large, mission-critical applications in Shiny. After this one-day workshop you will understand how to identify and troubleshoot problematic Shiny code, and how to build robust apps which are easy to maintain and extend.\nThe topics we will cover are:\n\nWhat is Shiny Core and why do we use it?\nBasics of Shiny modules\nCommunicating between modules\nTesting Shiny applications with pytest and playwright\n\n\n\nAudience\nThis course is for you if you:\n\nAre comfortable working with Python\nHave built and maintained a few Shiny applications in either R or Python\nAre comfortable with Shiny concepts like reactive calcuations and effect\n\nThis course is probably not for you if: - You aren’t really comfortable with Python - You are picking up Shiny for the first time\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nInstructor bio, including link to homepage."
  },
  {
    "objectID": "workshops/r_in_production.html",
    "href": "workshops/r_in_production.html",
    "title": "R in Production",
    "section": "",
    "text": "Description\nWhat it means to put R in production varies tremendously from organisation to organisation. However, I believe that there are common principles that you can learn to improve your code, regardless of the precise details of what production means for your organisation.\nThis workshop is organised around three big differences between running a local script on your computer and putting your code into production:\n\nNot just once: production code isn’t a one-off script; it runs repeatedly, and needs to run reliably even as the environment around it (e.g. R package versions and input data) changes. How can you ensure that code continues to run reliably months and years after you wrote it, and when there’s a problem it clearly reports on it.\nNot just your computer: production code doesn’t run on your computer. It typically runs on some other server where you can’t interactively experiment. This poses particular challenges for authentication and debugging.\nNot just you: the responsibility for production code is typically shared across a team. How can you ensure that you’re all working together as effectively as possible, sharing code and best practices, and continuing to get better at your job over time.\n\n\n\nAudience\nThis course is for you if you:\n\nGet frustrated debugging R code that’s running on another computer.\nStruggle keep your code running reliably as packages and data change over time.\nWant to generally improve the quality of your production code.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nHadley is Chief Scientist at Posit PBC, winner of the 2019 COPSS award, and a member of the R Foundation. He builds tools (both computational and cognitive) to make data science easier, faster, and more fun. His work includes packages for data science (like the tidyverse, which includes ggplot2, dplyr, and tidyr)and principled software development (e.g. roxygen2, testthat, and pkgdown). He is also a writer, educator, and speaker promoting the use of R for data science. Learn more on his website, http://hadley.nz."
  },
  {
    "objectID": "workshops/tables.html",
    "href": "workshops/tables.html",
    "title": "Making Tables with gt and Great Tables",
    "section": "",
    "text": "Description\nThe gt package for R and the Great Tables package for Python both deal with an important element of written communication: tables. We don’t believe tables have to be drab or dull. Rather, we think that tables have the power to inspire and to excite!\nIn this workshop, you’ll learn about how to make tables that can accurately convey information yet look aesthetically pleasing. We will handle the first stumbling block: what do we even call the different parts of a table? After getting the table terminology down we’ll learn how to effectively assemble the table components and create powerful displays of information. We will start simply and progressively, working toward more complex table designs. Since there are two packages (one in R, one in Python) we will take a blended approach and learn about table generation in bilingual fashion.\nWe’ll cover the following:\n\nCreate table components and put them together (e.g., header, footer, stub, etc.)\nFormat cell values (numeric/scientific, date/datetime, etc.)\nRearranging columns and handling column value alignments\nStyling the table, either through data values or on a more granular level\nAdding icons, plots, images, and incorporating your own HTML\nmore!\n\n\n\nAudience\nThis course is for you if you:\n\nhave some basic working knowledge of either R or Python (separate sets of materials will be available for both R and Python),\nhave data you often need to present as data summaries\nwould like to level-up your ability to generate tables for publication\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nRichard Iannone (he/him) is a software engineer at Posit, PBC. He mainly works on open-source packages; here is a short list of packages that he is focused on: gt, Great Tables, and blastula.\n\n\n\n\nMichael Chow. Human memory, statistics, and computing."
  },
  {
    "objectID": "workshops/posit_tools_r.html",
    "href": "workshops/posit_tools_r.html",
    "title": "Data Science Workflows with Posit Tools — R Focus",
    "section": "",
    "text": "Description\nIn this R-focused workshop, we will discuss ways to improve your data science workflows! During the course, we will review packages for data validation, alerting, modeling, and more. We’ll use Posit’s open source and professional tools to string all the pieces together for an efficient workflow. We’ll discuss environments, managing deployed content, working with databases, and interoperability across data products.\n\n\nAudience\nThis course is for you if you:\n\nBuild finished data products starting from raw data and are looking to improve your workflow\nAre looking to expand your knowledge of Posit open source and professional tools\nWant to improve interoperability between data products in your work or on your team\nHave experience developing in R. An analogous course with a Python focus is also offered.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nRyan Johnson is a Data Science Advisor at Posit with a background in Microbiology and Bioinformatics. He obtained his PhD from the Uniformed Services University in Maryland and did his postdoctoral training at the National Human Genome Research Institute, NIH. The only thing that rivals his love for infectious diseases is generating ‘super cool’ visualizations from large data sets using R and RStudio. In his free time, you can find Ryan running marathons/ultramarathons in the DC area or hiking miles along the Appalachian Trail. Ryan resides in Gaithersburg with his wife and two feline co-workers.\n\n\n\n\nKatie Masiello is a Solutions Engineer at Posit. A mechanical engineer by training, she found her calling in data science while working statistical analysis in the aerospace industry. A good cup of coffee, reproducibility, and making life easier for the next user are three things she loves most. Katie is an avid knitter and knitr, and she can often be found trying to tame her ridiculously overgrown garden, collecting pebbles, or thinking about taking up running as a hobby."
  },
  {
    "objectID": "workshops/vetiver.html",
    "href": "workshops/vetiver.html",
    "title": "Intro to MLOps with vetiver",
    "section": "",
    "text": "Description\nData scientists understand what goes into training a machine learning or statistical model, but bringing that model into a production environment can be daunting.\nThis workshop will cover the fundamentals of MLOps (machine learning operations), the practices used to create a MLOps strategy, and what kinds of tasks and components are involved. We’ll use vetiver, a framework for MLOps tasks in Python and R, to version, deploy, and monitor the models you have trained and want to deploy and maintain in production reliably and efficiently.\n\n\nAudience\nWe expect participants to have exposure to basic modeling and machine learning practice, but NOT expert familiarity with advanced ML or MLOps topics.\nThis workshop is for you if you:\n\nhave intermediate R or Python knowledge (this will be a “choose your own adventure” workshop where you can work through the exercises in either R or Python),\ncan read data from CSV and other flat files, transform and reshape data, and make a wide variety of graphs, and\ncan fit a model to data with your modeling framework of choice.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nIsabel Zimmerman(she/her) is a software engineer at Posit, PBC. As part of her job at Posit, she builds and maintains MLOps Python packages such as vetiver and pins. She has a background as a software engineer/data scientist working with data and models in cloud environments."
  },
  {
    "objectID": "workshops/shiny_python_intro.html",
    "href": "workshops/shiny_python_intro.html",
    "title": "Introduction to Shiny for Python",
    "section": "",
    "text": "Description\nShiny for Python is a new framework for building performant, beautiful web applications in Python. In this one-day workshop, you will learn the basic building blocks of a Shiny application which will let you create both quick, simple applications and elaborate mission-critical ones.\nIn particular this workshop covers:\n\nThe basics of building a Shiny for Python app\nWhen to use reactive calculations and reactive effects\nHow modules can help you develop reusable components\nTheming and deploying your application\n\nAt the end of this course you will be able to:\n\nBuild a Shiny app in Python\nArticulate how Shiny differs from other frameworks\nUtilize best practices to make sure your app is robust and scalable\n\n\n\nAudience\nThis course is for you if you are:\n\nA Python programmer interested in quickly building efficient web applications\nAn educator interested in integration Shiny apps into your python course\nAn R programmer interested in building Shiny apps in Python\n\n\n\nFAQ\n\nWhat if I’m a complete beginner?\n\nYou should have a basic understanding of Python and be able to install packages with pip, do basic data manipulation, and draw plots.\n\nWhat if I’ve never built a Shiny app before?\n\nThis workshops doesn’t require any Shiny or web application experience. We will start from scratch to build simple applications before moving on to more complex ones.\n\nWhy should I learn Shiny if I already know Streamlit or Dash?\n\nWe believe that Shiny is the best framework for building data applications in Python. It’s reactive execution model means that you can build performant applications without explicitly caching data or managing application state. See this blog post for more on why we think that Shiny is worth learning.\n\nI’m an expert with Shiny for R, is this workshop for me?\n\nThe R and Python Shiny packages are quite similar, so some of the content in this workshop may be familiar to you. That said it’s a great opportunity to fill in missing pieces and ask question about Python best practices. Check out our quickstart guide for R users and this tutorial if you want to quickly get up to speed with Shiny for Python.\n\n\nInstructors\n\n\n\n\n\n\n\n\n\n\n\nGarrett is Director of Education at Posit PBC. He is a contributor to the Shiny for Python website, and the co-author of several data science books including, R for Data Science.\n\n\n\n\n\nAndrie is Director of Product Strategy at Posit. He started using R in 2009 for market research statistics and joined Revolution Analytics in 2013, assisting customers with their adoption of R for machine learning. After the acquisition of Revolution analytics by Microsoft in 2015, he implemented deep learning and machine learning projects in the Azure cloud."
  },
  {
    "objectID": "workshops/intro_ds_python.html",
    "href": "workshops/intro_ds_python.html",
    "title": "Introduction to Data Science with Python",
    "section": "",
    "text": "Description\nThis is not a standard workshop, but a six-week online apprenticeship that culminates in-person at posit::conf(2024).\nHere, you will learn the foundations of Python for data science under the guidance of a Posit Academy mentor and in the company of a close group of fellow learners. You will be expected to complete a weekly curriculum of interactive tutorials, and to attend a weekly presentation meeting with your mentor and fellow learners. Topics will include importing packages and datasets, visualizing data with plotnine, wrangling data with pandas, and reporting reproducibly with Quarto.\nNo prior knowledge of Python required. Visit posit.co/academy to learn more about this uniquely effective learning format.\n\n\n\n\n\n\nImportant dates\n\n\n\n🗓️ Online sessions begin the week of July 1st, 2024.\n🚫 Registration for this workshop will close on June 24th, 2024.\n\n\n\n\nAudience\nThis course is for you if you:\n\nare new to Python,\nhave dabbled in Python, but are not sure how to use Python to do data science, or\nare an R user who wants to work more closely with Python users on your team.\n\n\n\nInstructors\n\n\n\n\n\n\n\n\n\n\nPosit Academy is Posit’s internal team of data scientists and educators. We provide a cohort-based, mentor-led, hands-on data science apprenticeship for working professionals. It is delivered on an online platform with interactive coding exercises and frequent cross-learner collaboration."
  },
  {
    "objectID": "workshops/shiny_r_adv.html",
    "href": "workshops/shiny_r_adv.html",
    "title": "Advanced to Shiny for R",
    "section": "",
    "text": "Description\nFull workshop description goes here. Multi-paragraph ok.\n\n\nAudience\nThis course is for you if you:\n\nlist at least\nthree attributes\nfor your target audience\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nInstructor bio, including link to homepage."
  },
  {
    "objectID": "workshops/pkg_dev.html",
    "href": "workshops/pkg_dev.html",
    "title": "Package Development: The Rest of the Owl",
    "section": "",
    "text": "Description\nIn R, the fundamental unit of reusable and shareable code is a package, containing helpful functions, documentation, and sometimes sample data. Putting R code in a package is the best way to share our code with others or to share code across different projects.\nThis workshop assumes you’ve already dipped your toe in package development, i.e. that you’ve managed to create a basic package and pass R CMD check. In terms of “How to draw an owl”, you’ve definitely drawn some circles. But now it’s time to draw the rest of the owl!\n\nYou will learn workflows and skills that are (a) very important for package development and (b) very different from writing R scripts. We will lean heavily on the tools and principles used by the tidyverse team, embodied in the devtools family of packages, including usethis, testthat, and roxygen2.\nThe exact topics won’t be finalized until closer to conf, but they are likely to be drawn from this list:\n\nFundamental daily workflows: devtools::load_all() and check()\nDocumentation: function documentation, vignettes, and website\nDependencies and namespaces: how to use other packages in yours and how to distinguish the parts of your package that are internal vs. external\nTesting: the testthat package and the philosophy of writing tests as you go (vs. “later”)\nDebugging: beyond print statements\nData: internal data vs. data available to your user\n\nIt is likely we will reserve a chunk of time late in the day for you to apply something you’ve learned to your own package(s). This is a good chance to talk things through with members of the tidyverse team.\nThis will be an interactive 1-day workshop, and we will be using the RStudio IDE to work through the materials.\n\n\nAudience\nThis course is for you if you:\n\nAre very comfortable writing R scripts and functions.\nHave already created a basic package, e.g., you’ve successfully worked through The Whole Game chapter from R Packages or have equivalent experience.\nHave concrete plans for one or more specific packages you want to create. You might have even started implementing these plans.\nAre interested in using devtools/RStudio for package development.\nAre at least curious about Git/GitHub. We won’t have time to teach this explicitly, but you will certainly see Git/GitHub through out the day.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nJenny is a software engineer at Posit, usually working on the tidyverse packages or its supporting ecosystem, and is a member of the R Foundation. She recently co-authored the second edition of the R Packages book and is the maintainer of the devtools and usethis packages (among others)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workshops",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Instructor(s)\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nInstructor(s)\n\n\nDescription\n\n\n\n\n\n\nAdvanced Shiny for Python\n\n\nGordon Shotwell\n\n\nTake your Shiny apps to the next level with modules \n\n\n\n\nAdvanced Tidymodels\n\n\nMax Kuhn\n\n\nAn advanced class to learn how to use tidymodels to optimize different models, conduct feature engineering, and other activities. \n\n\n\n\nAdvanced to Shiny for R\n\n\nInstructor 1 name, Instructor 2 name (remove if single instructor)\n\n\n1-sentence summary of workshop. \n\n\n\n\nBig Data in R with Arrow\n\n\nNic Crane, Steph Hazlitt\n\n\nAn introduction to Apache Arrow for creating efficient analysis pipelines with larger-than-memory data in R. \n\n\n\n\nBuild-a-Dashboard Workshop (with Quarto, R and/or Python)\n\n\nMine Çetinkaya-Rundel\n\n\nCreate sleek, elegant, and eye-catching dashboards with static and/or interactive elements with Quarto. For R and Python users. \n\n\n\n\nCausal Inference in R\n\n\nMalcolm Barrett, Travis Gerke\n\n\nLearn to answer causal questions with causal diagrams, propensity score modeling, and more. \n\n\n\n\nData Science Workflows with Posit Tools — Python Focus\n\n\nSam Edwardes, Gagandeep Singh\n\n\nBuild an opinionated and Pythonic data science workflow using Posit’s professional products and open-source tools. \n\n\n\n\nData Science Workflows with Posit Tools — R Focus\n\n\nRyan Johnson, Katie Masiello\n\n\nUse open source packages and Posit’s professional tools — Workbench, Connect, and Package Manager — to improve your end-to-end data science workflows. \n\n\n\n\nDatabases (Details TBD)\n\n\nInstructor 1 name, Instructor 2 name (remove if single instructor)\n\n\n1-sentence summary of workshop. \n\n\n\n\nDataviz (Details TBD)\n\n\nInstructor 1 name, Instructor 2 name (remove if single instructor)\n\n\n1-sentence summary of workshop. \n\n\n\n\nDevOps for Data Scientists\n\n\nRika Gorn\n\n\nThis workshop is intended for data scientists who wish to learn more about the basic principles and tools of DevOps and to get hands-on experience putting DevOps workflows into production. \n\n\n\n\nFrom R User to R Programmer\n\n\nEmma Rand, Ian Lyttle\n\n\nImprove your R programming skills and reduce the amount of duplication in your code. \n\n\n\n\nIntro to MLOps with vetiver\n\n\nIsabel Zimmerman\n\n\nUtilize the vetiver framework in Python and R for efficient versioning, deployment, and monitoring of machine learning models in production. \n\n\n\n\nIntroduction to Data Science with Python\n\n\nPosit Academy Team\n\n\nLearn the foundations of Python for data science through a cohort-based, mentor-led, hands-on apprenticeship for working professionals. \n\n\n\n\nIntroduction to Data Science with R and Tidyverse\n\n\nPosit Academy Team\n\n\nLearn the foundations of R for data science through a cohort-based, mentor-led, hands-on apprenticeship for working professionals. \n\n\n\n\nIntroduction to Quarto\n\n\nAndrew Bray\n\n\nAuthor a rich array of documents in Quarto. \n\n\n\n\nIntroduction to Shiny for Python\n\n\nGarrett Grolemund, Andrie de Vries\n\n\nLearn the basic building blocks of Shiny for Python, including the new Shiny Express syntax. \n\n\n\n\nIntroduction to Shiny for R\n\n\nColin Rundel\n\n\nIntroduction to builing interactive web apps using Shiny and R \n\n\n\n\nIntroduction to tidymodels\n\n\nHannah Frick, Simon Couch\n\n\nMachine learning with tabular data using the tidymodels framework. \n\n\n\n\nML Python (Details TBD)\n\n\nInstructor 1 name, Instructor 2 name (remove if single instructor)\n\n\n1-sentence summary of workshop. \n\n\n\n\nMaking Tables with gt and Great Tables\n\n\nRichard Iannone, Michael Chow\n\n\nCreate publication-quality tables with gt and Great Tables. For R and Python users. \n\n\n\n\nPackage Development: The Rest of the Owl\n\n\nJenny Bryan\n\n\nLearn what’s different about writing R code that lives in a package (vs. a script). \n\n\n\n\nQuarto Websites\n\n\nCharlotte Wickham, Emil Hvitfeldt\n\n\nBuild a website from scratch with Quarto. \n\n\n\n\nR in Production\n\n\nHadley Wickham\n\n\nLearn how to write robust R code that both works reliably in production, and when it fails, is easy to debug. \n\n\n\n\nUsing Databricks with R\n\n\nEdgar Ruiz\n\n\nOverview of the latests methods to connect, and interact with Databricks services. \n\n\n\n\nWhat They Forgot To Teach You About R\n\n\nShannon Pileggi, E. David Aja\n\n\nThis workshop is designed to level up experienced R programmers in debugging and personal R administration. \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshops/databases.html",
    "href": "workshops/databases.html",
    "title": "Databases (Details TBD)",
    "section": "",
    "text": "Description\nFull workshop description goes here. Multi-paragraph ok.\n\n\nAudience\nThis course is for you if you:\n\nlist at least\nthree attributes\nfor your target audience\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nInstructor bio, including link to homepage."
  },
  {
    "objectID": "workshops/ml_python.html",
    "href": "workshops/ml_python.html",
    "title": "ML Python (Details TBD)",
    "section": "",
    "text": "Description\nFull workshop description goes here. Multi-paragraph ok.\n\n\nAudience\nThis course is for you if you:\n\nlist at least\nthree attributes\nfor your target audience\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nInstructor bio, including link to homepage."
  },
  {
    "objectID": "workshops/posit_tools_python.html",
    "href": "workshops/posit_tools_python.html",
    "title": "Data Science Workflows with Posit Tools — Python Focus",
    "section": "",
    "text": "Description\nThis Python-focused workshop will discuss ways to improve your data science workflows! During the course, we will review packages for data validation, alerting, modelling, and more. We’ll use Posit’s open-source and professional tools to string all the pieces together for an efficient workflow. We’ll discuss environments, managing deployed content, working with databases, and interoperability across data products.\n\n\nAudience\nThis course is for you if you:\n\nBuild finished data products starting from raw data and are looking to improve your workflow\nAre looking to expand your knowledge of Posit open source and professional tools\nWant to improve interoperability between data products in your work or on your team\nHave experience developing in Python. An analogous course with an R focus is also offered\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nSam Edwardes is obsessed with data science, R, Python, and all things open source. As a Solutions Engineer at Posit, he loves getting into the nitty gritty and optimizing everything. When he is not tinkering on his computer, you can find Sam and his dog Roo on adventures in beautiful British Columbia.\n\n\n\n\nGagandeep Singh is a former software engineer and data scientist who has worked in a variety of cross-technology teams. Before joining Posit as a Solutions Engineer, he consulted with Fortune 500 companies to build their analytical capacities. Outside of work, you can find him at a local bookstore."
  },
  {
    "objectID": "workshops/quarto_intro.html",
    "href": "workshops/quarto_intro.html",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "Description\nThis workshop will prepare you to author a rich array of documents in Quarto, the next generation of R Markdown. Quarto is an open-source scientific and technical publishing system that offers multilingual programming language support to create dynamic and static documents, books, presentations, blogs, and other online resources.\nThe focus for this workshop will be on single documents. You will learn to create static documents, to add interactivity to them with Shiny and htmlwidgets, or steer them in the direction of sophisticated scientific documents. In the afternoon you’ll take the same authoring approaches to create slide presentations in various formats such as reveal.js, beamer, and pptx.\n\n\nAudience\nThis course is for you if you:\n\nhave a basic knowledge of how to use the RStudio IDE,\nhave some familiarity with markdown, or\nare excited to author flexible single documents like technical reports and slide presentations.\n\nSeasoned users of R Markdown will get more out of the Advanced Quarto with R and RStudio: Projects, Websites, Books, and More workshop, which is focused on projects, a distinct strength of Quarto in authoring work that spans multiple documents.\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nAndrew Bray is an Associate Teaching Professor in the Department of Statistics at UC Berkeley where he develops and teaches courses in statistics and data science. His research interests include statistical computing, data privacy, and applications of statistical models to solve real world problems. He was previously an Associate Professor of Statistics in the Department of Mathematics at Reed College and an NSF Five Colleges postdoctoral fellow in western Massachusetts."
  },
  {
    "objectID": "workshops/tidymodels_advanced.html",
    "href": "workshops/tidymodels_advanced.html",
    "title": "Advanced Tidymodels",
    "section": "",
    "text": "Description\nIn this workshop you will learn more about model optimization using the tune and finetune packages, including racing and iterative methods. You’ll be able to do more sophisticated feature engineering with recipes.\nTime permitting, model ensembles via stacking will be introduced.\nThis course is focused on the analysis of tabular data and does not include deep learning methods.\n\n\nAudience\nThis workshop is for you if you:\n\nhave used tidymodels packages like recipes, rsample, and parsnip.\nare comfortable with tidyverse syntax (e.g. piping, mutates, pivoting), and\nhave some experience with resampling and modeling (e.g., linear regression, random forests, etc.), but we don’t expect you to be an expert in these.\n\nParticipants who are new to tidymodels will benefit from taking the Introduction to tidymodels workshop before joining this one.\n\n\nInstructor\n\n\n\n\n\n\n\n\n\n\nMax Kuhn is a software engineer at Posit. He is responsible for the tidymodels ecosystem and maintains about 30 packages, including caret. He was applying models in the pharmaceutical and diagnostic industries for over 18 years. Max has a Ph.D. in Biostatistics. He, and Kjell Johnson, wrote the book Applied Predictive Modeling, which won the Ziegel award from the American Statistical Association. Their second book, Feature Engineering and Selection, was published in 2019 and the book Tidy Models with R was published in 2022. He is currently working on Applied Machine Learning for Tabular Data"
  },
  {
    "objectID": "workshops/quarto_websites.html",
    "href": "workshops/quarto_websites.html",
    "title": "Quarto Websites",
    "section": "",
    "text": "Description\nDo you need a professional website to showcase your work? Or have you got an idea for a website at work, but it needs to reflect your organization’s brand? If you’ve used Quarto to produce a document, you’ve already got the technical skills to create a Quarto website. In this workshop, you’ll learn everything else you need to build a website and customize its appearance.\nYou’ll get a running start by using a template we’ve designed to be functional and attractive, but also act as a guide for your learning. Then you’ll:\n\nAdd pages and navigation, and learn best practices for structuring your content.\nCustomize the visual appearance of your site by mastering the basics of SCSS and CSS and how they apply to Quarto websites.\nUse listings, a special kind of page, to showcase related content like blog posts, projects, or talks.\n\nBy the end of the workshop you’ll have built and published (if you want) a personal website, but the same tools and techniques will apply to any kind of website you might like to build.\nWe’ll assume you’ve used Quarto to produce documents, but we won’t assume you have any HTML, CSS/SCSS or Git/GitHub experience, nor will we assume any particular programming language (R, Python etc.) or level of programming experience.\n\n\nAudience\nThis course is for you if you:\n\nHave used Quarto to generate documents (e.g. HTML, PDF, MS Word etc.)\nAre comfortable editing plain text documents (e.g .qmd) in your IDE (e.g. RStudio, Visual Studio Code etc.)\nWant to walk away with your own personal website\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nDr. Charlotte Wickham (she/her) is a Developer Educator on the Quarto team at Posit. As part of her job at Posit, Charlotte helps to keep quarto.org—a website about, and also built with, Quarto—up to date. Prior to Posit, she taught Statistics and Data Science at Oregon State University where she received awards for her in-person and online teaching.\n\n\n\n\nEmil Hvitfeldt (he/him) is a Software Engineer on the tidymodels team at Posit. Emil works on making modeling easy and intuitive with tidy tools. Outside of modeling, he is also trying to make slidecrafting a well respecting verb."
  },
  {
    "objectID": "workshops/arrow.html",
    "href": "workshops/arrow.html",
    "title": "Big Data in R with Arrow",
    "section": "",
    "text": "Description\nData analysis pipelines with larger-than-memory data are becoming more and more commonplace. In this workshop you will be introduced to Apache Arrow, a multi-language toolbox for working with larger-than-memory tabular data, to create seamless “big” data analysis pipelines with R.\nThis workshop will focus on using the the arrow R package—a mature R interface to Apache Arrow—to process larger-than-memory files and multi-file data sets with arrow using familiar dplyr syntax. You’ll learn to create and use the interoperable data file format Parquet for efficient data storage and access, with data stored both on disk and in the cloud, and also how to exercise fine control over data types to avoid common large data pipeline problems. Designed for new-to-arrow R users, this workshop will provide a foundation for using Arrow, giving you access to a powerful suite of tools for performant analysis of larger-than-memory tabular data in R.\n\n\nAudience\nThis course is for you if you:\n\nwant to learn how to work with tabular data that is too large to fit in memory using existing R and tidyverse syntax implemented in Arrow\nwant to learn about Parquet, a powerful file format alternative to CSV files\nwant to learn how to engineer your tabular data storage for more performant access and analysis with Apache Arrow\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nNic Crane is an R consultant with a background in data science and software engineering. They are passionate about open source, and learning and teaching all things R. Nic is part of the core team that maintain the Arrow R package, and a co-author of “Scaling up with R and Arrow”, due to be published by CRC Press later this year.\n\n\n\n\nSteph Hazlitt is a data scientist, researcher and R enthusiast. She has spent the better part of her career wrangling data with R and supporting people and teams in creating and sharing data science-related products and open source software. Steph is the Director of Data Science Partnerships with BC Stats."
  },
  {
    "objectID": "workshops/causal.html",
    "href": "workshops/causal.html",
    "title": "Causal Inference in R",
    "section": "",
    "text": "Description\nIn this workshop, we’ll teach the essential elements of answering causal questions in R through causal diagrams, and causal modeling techniques such as propensity scores and inverse probability weighting.\nIn both data science and academic research, prediction modeling is often not enough; to answer many questions, we need to approach them causally. In this workshop, we’ll teach the essential elements of answering causal questions in R through causal diagrams, and causal modeling techniques such as propensity scores and inverse probability weighting. We’ll also show that by distinguishing predictive models from causal models, we can better take advantage of both tools. You’ll be able to use the tools you already know–the tidyverse, regression models, and more–to answer the questions that are important to your work.\n\n\nAudience\nThis course is for you if you:\n\nknow how to fit a linear regression model in R,\nhave a basic understanding of data manipulation and visualization using tidyverse tools, and\nare interested in understanding the fundamentals behind how to move from estimating correlations to causal relationships.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nMalcolm Barrett is an epidemiologist and research software engineer at Stanford University. After receiving his Ph.D. in epidemiology from the University of Southern California, he worked as a data scientist at Apple and Posit. His work has focused on causal inference methodology and software development, including many R packages for causal inference.\n\n\n\n\n\n\n\n\n\nTravis Gerke, Sc.D., is Director of Data Science at the PCCTC, a contract research organization that facilitates clinical trials and real-world evidence studies in oncology. He is also co-founder and chief scientific officer of cStructure, a technology company built to empower teams with a collaborative causal design and inference platform."
  },
  {
    "objectID": "workshops/intro_ds_r.html",
    "href": "workshops/intro_ds_r.html",
    "title": "Introduction to Data Science with R and Tidyverse",
    "section": "",
    "text": "Description\nThis is not a standard workshop, but a six-week online apprenticeship that culminates in-person at posit::conf(2024).\nHere, you will learn the foundations of R and the Tidyverse under the guidance of a Posit Academy mentor and in the company of a close group of fellow learners. You will be expected to complete a weekly curriculum of interactive tutorials, and to attend a weekly presentation meeting with your mentor and fellow learners. Topics will include the basics of R, importing, visualizing and wrangling data with the tidyverse, and reporting reproducibly with Quarto.\nNo prior knowledge of R required. Visit posit.co/academy to learn more about this uniquely effective learning format.\n\n\n\n\n\n\nImportant dates\n\n\n\n🗓️ Online sessions begin the week of July 1st, 2024.\n🚫 Registration for this workshop will close on June 24th, 2024.\n\n\n\n\nAudience\nThis course is for you if you:\n\nare new to R or the Tidyverse,\nhave dabbled in R, but now want a rigorous foundation in up-to-date data science best practices, or\nare a SAS or Excel user looking to switch your workflows to R.\n\n\n\nInstructors\n\n\n\n\n\n\n\n\n\n\nPosit Academy is Posit’s internal team of data scientists and educators. We provide a cohort-based, mentor-led, hands-on data science apprenticeship for working professionals. It is delivered on an online platform with interactive coding exercises and frequent cross-learner collaboration."
  },
  {
    "objectID": "workshops/quarto_dashboards.html",
    "href": "workshops/quarto_dashboards.html",
    "title": "Build-a-Dashboard Workshop (with Quarto, R and/or Python)",
    "section": "",
    "text": "Description\nYou already analyze and summarize your data in computational notebooks with R and/or Python. What’s next? You can share your insights or allow others to make their own conclusions in eye-catching dasboards and straight-forward to author, design, and deploy Quarto Dashboards, regardless of the language of your data processing, visualization, analysis, etc. With Quarto Dashboards, you can create elegant and production-ready dashboards using a variety of components, including static graphics (ggplot2, Matplotlib, Seaborn, etc.), interactive widgets (Plotly, Leaflet, Jupyter Widgets, htmlwidgets, etc.), tabular data, value boxes, text annotations, and more. Additionally, with intelligent resizing of components, your Quarto Dashboards look great on devices of all sizes. And importantly, you can author Quarto Dashboards without leaving the comfort of your “home” – in plain text markdown with any text editor (VS Code, RStudio, Neovim, etc.) or any notebook editor (JupyterLab, etc.). This workshop will walk you through building an increasingly complex dashboard using various layout options and and deploy them as static web pages (with no special server required) as well as with a Shiny Server on the backend for enhanced interactivity.\n\n\nAudience\nThis course is for you if you:\n\ndo data analysis in computational notebooks\nshare your results with your audience in static or interactive dashboards\nwant to improve the design, user interface, and experience of your dashboards\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nDr. Mine Çetinkaya-Rundel (she/her) is Professor of the Practice at Duke University and Developer Educator at Posit. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine works on integrating computation into the undergraduate statistics curriculum, using reproducible research methodologies and analysis of real and complex datasets. Mine works on the OpenIntro project, whose mission is to make educational products that are free, transparent, and lower barriers to education. As part of this project she co-authored four open-source introductory statistics textbooks. She is also the creator and maintainer of datasciencebox.org and she teaches the popular Statistics with R MOOC on Coursera. Mine is a Fellow of the ASA and Elected Member of the ISI as well as the winner of the 2021 Robert V. Hogg Award for Excellence in Teaching Introductory Statistics."
  },
  {
    "objectID": "workshops/databricks.html",
    "href": "workshops/databricks.html",
    "title": "Using Databricks with R",
    "section": "",
    "text": "Description\nAs most organization’s data migrate to the cloud, the ability to analyze data in-place becomes more important. This workshop will walk you through how to think about remote data, how to access it, and how to analyze it efficiently. We will review the latest in integrations between R and Databricks. The two integrations that we will review are:\n\nSpark via Databricks Connect\nODBC connection\n\nDuring the workshop, we will discuss best practices for when to use which integration, as well as techniques to take your analysis into production.\n\n\nAudience\nThis course is for you if you:\n\nAre an R user\nPlan, or are currently, using Databricks services\nNeed to learn how to access and analyze data in Databricks\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nEdgar co-authored a book called “Mastering Spark with R,” and is currently the maintainer of the sparklyr package. Edgar has also authored multiple articles, blog posts sharing analytics insights, and server infrastructure for data science. He has a background in deploying enterprise reporting, and business intelligence solutions.\nhttps://www.linkedin.com/in/edgararuiz/"
  },
  {
    "objectID": "workshops/dev_ops.html",
    "href": "workshops/dev_ops.html",
    "title": "DevOps for Data Scientists",
    "section": "",
    "text": "Description\nIn this course we will learn the key principles of DevOps and problems which it intends to solve for data scientists. We will discuss how DevOps practices such as CI/CD enhance collaboration, automation, and reproducibility. We will learn common workflows for environment management, package management, containerization, monitoring & logging, and version control. Participants will get hands-on experience with a variety of tools including Docker, Github Actions, and APIs. Posit Pro Products will also be used by participants to quickly create and deploy R or python code using DevOps pipelines.\nPlease note that this course is not prescriptive around DevOps tools which are constantly growing and changing. Given that, the exact tools that will be used in this course (e.g. Jenkins, Azure Devops, etc) are subject to change.\n\n\nAudience\nThis course is for you if you:\n\nWant to learn the main principles and tools of DevOps\nAre a data scientist who wants to put their R/Python code into production or work more closely with DevOps teams\nWant to get hands-on experience using docker, CI/CD tools, and other DevOps workflows.\n\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nRika Gorn is a Senior Solutions Engineer at Posit where she helps customers and organizations create infrastructure for data analytics and data science. Her background is in data science and data engineering."
  },
  {
    "objectID": "workshops/tidymodels_intro.html",
    "href": "workshops/tidymodels_intro.html",
    "title": "Introduction to tidymodels",
    "section": "",
    "text": "Description\nThis workshop will teach you core tidymodels packages and their uses: data splitting/resampling with rsample, model fitting with parsnip, measuring model performance with yardstick, and basic pre-processing with recipes. Time permitting, you’ll be introduced to model optimization using the tune package. You’ll learn tidymodels syntax as well as the process of predictive modeling for tabular data.\n\n\nAudience\nThis workshop is for you if you:\n\nare comfortable using tidyverse packages to read data into R, transform and reshape data, and make a variety of graphs, and\nhave had some exposure to basic statistical concepts such as linear models, residuals, etc.\n\nIntermediate or expert familiarity with modeling or machine learning is not required. Interested students who have intermediate or expert familiarity with modeling or machine learning may be interested in the Advanced tidymodels workshop.\n\n\nInstructor(s)\n\n\n\n\n\n\n\n\n\n\nHannah Frick is a software engineer and statistician on the tidymodels team at Posit. She holds a PhD in statistics and has worked in data science consultancy as well as interdisciplinary research at University College London in cooperation with Team GB Hockey.\n\n\n\n\nSimon Couch works on software for statistical modeling on the tidymodels team at Posit. With a background in statistics and sociology, Simon is passionate about free and open source software and data pedagogy. He is an author and maintainer of several R packages, including the stacks package, which was awarded the 2021 John M. Chambers Statistical Software Award."
  }
]